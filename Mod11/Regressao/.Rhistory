install.packages('RMySQL')
install.packages('ggplot2')
install.packages('dbplyr')
install.packages('RMySQL')
install.packages('RMySQL')
library(RMySQL)
library(ggplot2)
library(dbplyr)
con = dbConnect(MySQL(),user = 'root', password='root',dbname='titanic',host='localhost')
dbGetQuery(con, query)
con = dbConnect(MySQL(),user = 'root', password='root',dbname='titanic',host='localhost')
query <- "select pclass, survived, avg(age) as media_idade WHERE survived = 1 GROUP BY survived"
dbGetQuery(con, query)
query <- "select pclass, survived, avg(age) as media_idade FROM titanic.titanic WHERE survived = 1 GROUP BY survived"
dados <- dbGetQuery(con, query)
ggplot(dados,aes(pclass, media_idade)+ geom_bar(stat="identity"))
query <- "select pclass, survived, avg(age) as media_idade FROM titanic.titanic WHERE survived = 1 GROUP BY pclass,survived"
dados <- dbGetQuery(con, query)
head(dados)
ggplot(dados,aes(pclass, media_idade)+ geom_bar(stat="identity"))
ggplot(dados,aes(pclass, media_idade))+ geom_bar(stat="identity")
ggplot(dados,aes(pclass, media_idade))
ggplot(dados,aes(pclass, media_idade))+ geom_bar(stat="identity")
con2 = src_mysql(MySQL(),user = 'root', password='root',dbname='titanic',host='localhost')
con2 = src_mysql(user = 'root', password='root',dbname='titanic',host='localhost')
library(dplyr)
con2 = src_mysql(user = 'root', password='root',dbname='titanic',host='localhost')
collect()
dados2 <- %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <-
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <- tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <-
con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
head(dados2)
?summarise
con2 = src_mysql(user = 'root', password='root',dbname='titanic',host='localhost')
dados2 <-
con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <-
con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <- con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
dados2 <- con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
install.packages('RMySQL')
install.packages("RMySQL")
install.packages("RMySQL")
library(RMySQL)
library(ggplot2)
library(dbplyr)
library(dplyr)
dados2 <- con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
con2 = src_mysql(user = 'root', password='root',dbname='titanic',host='localhost')
dados2 <- con2  %>%
tbl('titanic') %>%
select(pclass,sex,survived) %>%
group_by(pclass,sex) %>%
summarise(survavival_ratio = avg(survived)) %>%
collect()
View(dados2)
install.packages('devtools')
library(devtools)
install_github('mongosoup/rmongodb')
mongo <- mongo.create()
library(rmongodb)
mongo <- mongo.create()
mongo.is.connected(mongo)
if(mongo.is.connected(mongo)){
mongo.get.databases()
}
mongo.get.databases(mongo)
colecao <- "users.contatos"
mongo.count(colecao)
mongo.count(mongo,colecao)
res <- mongo.distinct(mongo,colecao,"city")
headr(res)
head(res)
typeof(res)
mongo.find.one(mongo,colecao)
resOne <- mongo.find.one(mongo,colecao)
View(resOne)
head(resOne)
resOne <- mongo.find.one(mongo,colecao)
head(resOne)
resOne <- mongo.find.one(mongo,colecao)
head(resOne)
print(resOne)
mongo.destroy(mongo)
setwd("~/projects/DataScience/R Azure ML/big_data_r_azure/Mod3/")
getwd()
setwd("~/projects/DataScience/R Azure ML/big_data_r_azure/Mod3/")
getwd()
setwd("~/projects/DataScience/R Azure ML/big_data_r_azure/Mod9")
mean(media)
media = c(10,20,30,40)
mean(media)
media = c(10,20,30,40,50)
mean(media)
mediana = c(10,20,30,40,50)
median(mediana)
print(median(mediana))
print(mean(media))
moda = function(dados){
vector = table(as.vector(dados))
names(vector)[vector == max(vector)]
}
moda(c(10,10,20,20,20,20,30,40))
list_amplitude = c(10,10,20,20,20,20,30,40)
max(list_amplitude)
min(list_amplitude)
print(max(list_amplitude))
print(min(list_amplitude))
list_amplitude = c(10,10,20,20,20,20,30,40)
print(diff(range(list_amplitude)))
list_quartil = c(54, 55, 56, 57, 58, 59, 60, 61, 62, 63)
quartil(list_quartil)
quartile(list_quartil)
quantile(list_quartil)
list_quartil = c(54, 55, 56, 57, 58, 59, 60, 61, 62, 63,64)
quantile(list_quartil)
list_quartil = c(54, 55, 56, 57, 58, 59, 60, 61, 62, 63,64)
quantile(list_quartil,c(.10))
Maq1 = c(181.9, 180.8, 181.9, 180.2, 181.4)
Maq2 = c(180.1, 181.8, 181.5, 181.2, 182.4)
Maq3 = c(182.1, 183.7, 182.1, 180.2, 181.9)
mean(Maq1)
mean(Maq2)
mean(Maq3)
sd(Maq1)
sd(Maq2)
sd(Maq3)
dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,
30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,
37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,
45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65)
hist(dados, main = "Número de acidentes diários", xlab = 'Acidentes', ylab = 'Frequência')
```{r echo=FALSE}
dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,
30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,
37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,
45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65)
hist(dados, main = "Número de acidentes diários", xlab = 'Acidentes', ylab = 'Frequência')
hist(dados, main = "Número de acidentes diários", xlab = 'Acidentes', ylab = 'Frequência', breaks = 5)
mean(dados_assimetria)
sd(dados_assimetria)
median(dados_assimetria)
#Histograma mostra o que parece ser uma assimetria
dados_assimetria = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,
30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,
37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,
45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65)
hist(dados_assimetria, main = "Número de Acidentes Diários", xlab = "Acidentes", ylab = "Frequência")
mean(dados_assimetria)
sd(dados_assimetria)
median(dados_assimetria)
library(moments)
install.packages("moments")
library(moments)
SK = skewness(dados)
print(SK)
dados_coeficiente = rnorm(1000)
SK = skewness(dados_coeficiente)
hist(dados_coeficiente)
print(SK)
hist(dados_coeficiente)
print(SK)
library(moments)
dados_coeficiente_kurtose = rnorm(1000)
CK = kurtosis(dados_coeficiente_kurtose)
hist(dados_coeficiente_kurtose)
print(CK)
dados_coeficiente_kurtose = rnorm(1000)
CK = kurtosis(dados_coeficiente_kurtose)
print(CK)
hist(dados_coeficiente_kurtose)
CK = kurtosis(dados_coeficiente_kurtose)
print(CK - 2.37652)
library(ggplot2)
library(ggplot2)
datasim <- data.frame(dados_coeficiente_kurtose)
ggplot(datasim, aes(x = dados_coeficiente_kurtose), binwidth = 2) +
geom_histogram(aes(y = ..density..), fill = 'red', alpha = 0.5) +
geom_density(colour = 'blue') + xlab(expression(bold('Dados'))) +
ylab(expression(bold('Densidade')))
dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,
30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,
37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,
45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65)
mean(dados)
sd(dados)
median(dados)
range(dados)
quantile(dados)
boxplot(dados, main = "Número de Acidentes Diários")
source('~/.active-rstudio-document', echo=TRUE)
my_data <- mtcars
head(my_data)
install.packages("ggpubr")
library("ggpubr")
install.packages("rstatix")
install.packages("car")
install.packages("rstatix", repos = "https://cloud.r-project.org")
install.packages("car", dependencies = TRUE)
install.packages("pbkrtest")
install.packages("ggpubr")
install.packages("ggpubr",dependencies=TRUE)
install.packages("rstatix",dependencies=TRUE)
install.packages("ggpubr",dependencies=TRUE)
install.packages("cowplot",dependencies=TRUE)
install.packages("tidyselect",dependencies=TRUE)
install.packages("tidyselect", dependencies = TRUE)
install.packages("car", dependencies = TRUE)
x <- rnorm(1000, 3, .25)
# Exercício 2 - Crie o histograma dos dados gerados no item anterior e adicione uma camada com a curva da normal.
hist(x, prob=TRUE, ylim=c(0,1.80), breaks=20, main = "Histograma de x")
curve(dnorm(x, 3, 0.25), add=TRUE, col="red", lwd=1)
# Exercício 3 - Suponha que 80% dos adultos com alergias relatem alívio sintomático com uma medicação específica.
# Se o medicamento é dado a 10 novos pacientes com alergias, qual é a probabilidade de que ele seja
# eficaz em exatamente sete?
?dbinom
dbinom(7, 10, 0.8)
graph <- function(n,p){
x <- dbinom(0:n,size=n,prob=p)
barplot(x,ylim=c(0,0.4),names.arg=0:n,
main=sprintf(paste('Binomial Distribution(n,p) ',n,p,sep=',')))
}
graph(10,0.8)
# Exercício 3 - Suponha que 80% dos adultos com alergias relatem alívio sintomático com uma medicação específica.
# Se o medicamento é dado a 10 novos pacientes com alergias, qual é a probabilidade de que ele seja
# eficaz em exatamente sete?
?dbinom
# Aplicamos a função pnorm da distribuição normal com média 72 e desvio padrão 15.2.
# Como estamos procurando a porcentagem de alunos com pontuação superior a 84,
# estamos interessados na cauda superior da distribuição normal.
pnorm(84, mean=72, sd=15.2, lower.tail=FALSE)
# Exercício 7 - Se houver 12 carros atravessando uma ponte por minuto, em média,
# encontre a probabilidade de ter 15 ou mais carros cruzando a ponte em um determinado minuto.
# A probabilidade de ter 14 ou menos carros atravessando a ponte em um determinado minuto é dada pela função ppois.
?ppois
# Assim, a probabilidade de ter 15 ou mais carros cruzando a ponte em um minuto está na
# cauda superior da função de densidade de probabilidade.
ppois(15, lambda=12, lower=FALSE)   # upper tail
# Como apenas uma das cinco respostas possíveis está correta, a probabilidade de responder corretamente
# a uma pergunta aleatória é 1/5 = 0,2. Podemos encontrar a probabilidade de ter exatamente 4 respostas
# corretas por tentativas aleatórias como segue.
dbinom(4, size=12, prob=0.2)
# Para encontrar a probabilidade de ter quatro ou menos respostas corretas por tentativas aleatórias,
# aplicamos a função dbinom com x = 0,…, 4.
dbinom(0, size=12, prob=0.2) +
dbinom(1, size=12, prob=0.2) +
dbinom(2, size=12, prob=0.2) +
dbinom(3, size=12, prob=0.2) +
dbinom(4, size=12, prob=0.2)
# Ou então:
pbinom(4, size=12, prob=0.2)
source('~/.active-rstudio-document', echo=TRUE)
# Exercício 1 - Construa o dataset pop_data com os dados de voos das
# companhias aéreas UA (United Airlines) e DL (Delta Airlines).
# O dataset deve conter apenas duas colunas, nome da companhia e atraso nos voos de chegada.
# Os dados devem ser extraídos do dataset flights para construir o dataset pop_data
# Vamos considerar este dataset como sendo nossa população de voos
View(flights)
View(flights)
# Pacotes
install.packages("dplyr")
install.packages('nycflights13')
library('ggplot2')
library('dplyr')
library('nycflights13')
# Exercício 1 - Construa o dataset pop_data com os dados de voos das
# companhias aéreas UA (United Airlines) e DL (Delta Airlines).
# O dataset deve conter apenas duas colunas, nome da companhia e atraso nos voos de chegada.
# Os dados devem ser extraídos do dataset flights para construir o dataset pop_data
# Vamos considerar este dataset como sendo nossa população de voos
View(flights)
pop_data <- na.omit(flights) %>%
filter(carrier == 'UA' | carrier == 'DL', arr_delay > 0)
View(pop_data)
pop_data <- na.omit(flights) %>%
filter(carrier == 'UA' | carrier == 'DL', arr_delay > 0) %>%
sample_n(17000)
View(pop_data)
View(DL)
DL <- na.omit(pop_data) %>%
filter(carrier == 'DL') %>%
sample_n(1000)
UA <- na.omit(pop_data) %>%
filter(carrier == 'UA') %>%
sample_n(1000)
View(DL)
DL$sample_id <- 1
View(DL)
DL$sample_id <- 2
pop_data <- na.omit(flights) %>%
select(carrier, arr_delay) %>%
filter(carrier == 'UA' | carrier == 'DL', arr_delay > 0) %>%
sample_n(17000)
DL <- na.omit(pop_data) %>%
filter(carrier == 'DL') %>%
sample_n(1000) %>%
DL$sample_id <- 1
DL$sample_id <- 1
DL <- na.omit(pop_data) %>%
filter(carrier == 'DL') %>%
sample_n(1000)
DL$sample_id <- 1
UA <- na.omit(pop_data) %>%
filter(carrier == 'UA') %>%
sample_n(1000)
DL$sample_id <- 2
DL$sample_id <- 1
UA$sample_id <- 2
View(DL)
delay <- merge(DL,UA)
View(delay)
View(DL)
delay <- merge(x=DL,y=UA)
delay <- merge(x=DL,y=UA, by = "sample_id")
View(delay)
delay <- rbind(DL,UA)
# Erro padrão
erro_padrao_amostra1 = sd(amostra1$arr_delay) / sqrt(nrow(amostra1))
# Erro padrão
erro_padrao_amostra1 = sd(UA$arr_delay) / sqrt(nrow(UA))
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
lower = mean(UA$arr_delay) - 1.96 * erro_padrao_amostra1
upper = mean(UA$arr_delay) + 1.96 * erro_padrao_amostra1
ic_1 = c(lower,upper)
mean(amostra1$arr_delay)
ic_1
mean(amostra1$arr_delay)
mean(UA$arr_delay)
# Exercício 5 - Calcule o intervalo de confiança (95%) da amostra2
erro_padrao_amostra2 = sd(DL$arr_delay) / sqrt(nrow(DL))
lower = mean(DL$arr_delay) - 1.96 * erro_padrao_amostra2
upper = mean(DL$arr_delay) + 1.96 * erro_padrao_amostra2
lower = mean(DL$arr_delay) - 1.96 * erro_padrao_amostra2
upper = mean(DL$arr_delay) + 1.96 * erro_padrao_amostra2
ic_2 = c(lower,upper)
mean(UA$arr_delay)
ic_2
toPlot = mutate(toPlot, upper = ifelse(toPlot$sample_id == 1,ic_1[2],ic_2[2]))
# Exercício 6 - Crie um plot Visualizando os intervalos de confiança criados nos itens anteriores
# Dica: Use o geom_point() e geom_errorbar() do pacote ggplot2
toPlot = summarise(group_by(delay, sample_id), mean = mean(arr_delay))
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1,ic_1[1],ic_2[1]))
toPlot = mutate(toPlot, upper = ifelse(toPlot$sample_id == 1,ic_1[2],ic_2[2]))
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id )) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.1)
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id )) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.1)
toPlot
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id )) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.1)
# Exercício 6 - Crie um plot Visualizando os intervalos de confiança criados nos itens anteriores
# Dica: Use o geom_point() e geom_errorbar() do pacote ggplot2
toPlot = summarise(group_by(delay, sample_id), mean = mean(arr_delay))
View(toPlot)
toPlot = mutate(toPlot, lower = ifelse(toPlot$sample_id == 1,ic_1[1],ic_2[1]))
toPlot = mutate(toPlot, upper = ifelse(toPlot$sample_id == 1,ic_1[2],ic_2[2]))
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id )) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.1)
View(toPlot)
View(toPlot)
dev.off()
ggplot(toPlot, aes(x = sample_id, y=mean, colour = sample_id )) +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.1)
# Scatterplot Matrix
install.packages("psych")
library(psych)
# Este gráfico fornece mais informações sobre o relacionamento entre as variáveis
pairs.panels(despesas[c("idade", "bmi", "filhos", "gastos")])
# Este gráfico fornece mais informações sobre o relacionamento entre as variáveis
pairs.panels(despesas[c("idade", "bmi", "filhos", "gastos")])
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
setwd("~/projects/DataScience/FCD/RAzureML/big_data_r_azure/Mod11/Regressao")
# Etapa 1 - Coletando os dados
despesas <- read.csv("despesas.csv")
View(despesas)
# Etapa 2: Explorando e Preparando os Dados
# Visualizando as variáveis
str(despesas)
# Medias de Tendência Central da variável gastos
summary(despesas$gastos)
# Construindo um histograma
hist(despesas$gastos, main = 'Histograma', xlab = 'Gastos')
# Tabela de contingência das regiões
table(despesas$regiao)
# Explorando relacionamento entre as variáveis: Matriz de Correlação
cor(despesas[c("idade", "bmi", "filhos", "gastos")])
# Visualizando relacionamento entre as variáveis: Scatterplot
# Perceba que não existe um claro relacionamento entre as variáveis
pairs(despesas[c("idade", "bmi", "filhos", "gastos")])
# Este gráfico fornece mais informações sobre o relacionamento entre as variáveis
pairs.panels(despesas[c("idade", "bmi", "filhos", "gastos")])
